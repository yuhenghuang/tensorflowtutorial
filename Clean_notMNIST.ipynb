{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "import feather"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this codebook is very slow. it takes approaximately 40 mins.\n",
    "#change the data_root before run it, if you are sure to have enough time\n",
    "\n",
    "data_root ='D:\\\\Programming\\\\Projects\\\\notMNIST'\n",
    "image_size=28\n",
    "\n",
    "def feather_3d(file,image_size = 28):\n",
    "    temp = feather.read_dataframe(file)\n",
    "    width = np.shape(temp.values)[1]\n",
    "    if width == 1:\n",
    "        final = temp.values\n",
    "    else:\n",
    "        final = np.reshape(temp.values, (-1, image_size, image_size))\n",
    "    return final\n",
    "\n",
    "def read_data(dir, filename):\n",
    "    file = os.path.join(dir, filename + '.feather')\n",
    "    output = feather_3d(file)\n",
    "    return output\n",
    "\n",
    "test_dataset = read_data(data_root, 'test_dataset')\n",
    "test_labels = read_data(data_root, 'test_labels')\n",
    "train_dataset = read_data(data_root, 'train_dataset')\n",
    "train_labels = read_data(data_root, 'train_labels')\n",
    "valid_dataset = read_data(data_root, 'valid_dataset')\n",
    "valid_labels = read_data(data_root, 'valid_labels')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The obs. in cleaned test data: 11801\n",
      "The obs. in cleaned training data: 197309\n",
      "The obs. in cleaned valid data: 19752\n"
     ]
    }
   ],
   "source": [
    "#filter blank images\n",
    "\n",
    "def dataclean(dataset,label,threshold=392.0):\n",
    "    leng=dataset.shape[0]\n",
    "    indicator=np.ones(leng, dtype=bool)\n",
    "    temp=0.1\n",
    "    for i in range(leng):\n",
    "        temp=dataset[i,:,:].sum()\n",
    "        if temp >= threshold or temp <= -threshold:\n",
    "            indicator[i] = 0\n",
    "    return dataset[indicator,:,:],label[indicator,:]\n",
    "\n",
    "test_dataset_clean, test_labels_clean = dataclean(test_dataset, test_labels, 378.0)\n",
    "train_dataset_clean, train_labels_clean = dataclean(train_dataset, train_labels, 378.0)\n",
    "valid_dataset_clean, valid_labels_clean = dataclean(valid_dataset, valid_labels, 378.0)\n",
    "\n",
    "print(\"The obs. in cleaned test data:\", test_dataset_clean.shape[0])\n",
    "print(\"The obs. in cleaned training data:\", train_dataset_clean.shape[0])\n",
    "print(\"The obs. in cleaned valid data:\", valid_dataset_clean.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200 in 1551  =  0.1289490651192779\n",
      "400 in 3040  =  0.13157894736842105\n",
      "600 in 4575  =  0.13114754098360656\n",
      "800 in 6073  =  0.13173061090070806\n",
      "1000 in 7537  =  0.1326787846623325\n",
      "1200 in 8985  =  0.1335559265442404\n",
      "1400 in 10415  =  0.13442150744119058\n",
      "Wall time: 22min 51s\n"
     ]
    }
   ],
   "source": [
    "#filter similar images in valid and test sets.\n",
    "#applied partial vectorization to accelerate the function though it is still very slow.\n",
    "\n",
    "def quick_delete(trainset, trainlabel, smallset, smalllabel):\n",
    "    leng_s=smallset.shape[0]\n",
    "    indicator=np.ones(leng_s, dtype=bool)\n",
    "    location=[]\n",
    "    k=0\n",
    "    train2d= trainset.reshape(-1, 28*28)\n",
    "    small2d= smallset.reshape(-1, 28*28)\n",
    "    for i in range(leng_s):\n",
    "        location = np.where(trainlabel==smalllabel[i,0])[0]\n",
    "        if not np.alltrue(np.linalg.norm(train2d[location,:] - small2d[i,:], axis=1)>0.27):\n",
    "            indicator[i] = 0\n",
    "            k +=1\n",
    "            if k % 200 == 0:\n",
    "                   print(k, 'in', i, ' = ', k/i)\n",
    "    return smallset[indicator,:,:], smalllabel[indicator,:]\n",
    "\n",
    "%time test_dataset_nooverlap, test_labels_nooverlap = quick_delete(train_dataset_clean, train_labels_clean, test_dataset_clean, test_labels_clean)\n",
    "%time valid_dataset_nooverlap, valid_labels_nooverlap = quick_delete(train_dataset_clean, train_labels_clean, valid_dataset_clean, valid_labels_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200 in 1551  =  0.1289490651192779\n",
      "400 in 3040  =  0.13157894736842105\n",
      "600 in 4575  =  0.13114754098360656\n",
      "800 in 6073  =  0.13173061090070806\n",
      "1000 in 7537  =  0.1326787846623325\n",
      "1200 in 8985  =  0.1335559265442404\n",
      "1400 in 10415  =  0.13442150744119058\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'valid_dataset_nooverlap' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-ee64e9a6b003>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[0mtest_dataset_nooverlap\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_labels_nooverlap\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdelete_overlap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_dataset_clean\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_labels_clean\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_dataset_clean\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_labels_clean\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"The obs. in nooverlap valid data:\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalid_dataset_nooverlap\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'valid_dataset_nooverlap' is not defined"
     ]
    }
   ],
   "source": [
    "#This is the old-version filter.\n",
    "#Do not run this cell!!\n",
    "#Do not!\n",
    "\n",
    "def delete_overlap(trainset, trainlabel, smallset, smalllabel):\n",
    "    leng_s=smallset.shape[0]\n",
    "    leng_t=trainset.shape[0]\n",
    "    indicator=np.ones(leng_s, dtype=bool)\n",
    "    location=[]\n",
    "    k=0\n",
    "    for i in range(leng_s):\n",
    "        location = np.where(trainlabel==smalllabel[i,0])[0]\n",
    "        for j in location:\n",
    "            if np.linalg.norm(smallset[i,:,:]-trainset[j,:,:])<=0.27:\n",
    "                indicator[i] = 0\n",
    "                k+=1\n",
    "                if k % 200 == 0:\n",
    "                   print(k, 'in', i, ' = ', k/i)\n",
    "                break\n",
    "    return smallset[indicator,:,:], smalllabel[indicator,:]\n",
    "\n",
    "#test_dataset_nooverlap, test_labels_nooverlap = delete_overlap(train_dataset_clean, train_labels_clean, test_dataset_clean, test_labels_clean)\n",
    "\n",
    "#print(\"The obs. in nooverlap valid data:\", test_dataset_nooverlap.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_dataset_final.feather already existed\n",
      "valid_dataset_final.feather already existed\n",
      "train_labels_final.feather already existed\n",
      "valid_labels_final.feather already existed\n"
     ]
    }
   ],
   "source": [
    "def save_feather3d(dataset, filename,image_size = 1, force = False):\n",
    "    dir = os.path.join(data_root, filename + '.feather')\n",
    "    if os.path.exists(dir) and not force:\n",
    "        print(filename + '.feather', \"already existed\")\n",
    "    else:\n",
    "        df = pd.DataFrame(dataset.reshape(-1, image_size))\n",
    "        feather.write_dataframe(df, dir)\n",
    "\n",
    "save_feather3d(train_dataset_clean, 'train_dataset_final',image_size)\n",
    "save_feather3d(test_dataset_nooverlap, 'test_dataset_final',image_size,True)\n",
    "save_feather3d(valid_dataset_clean, 'valid_dataset_final',image_size)\n",
    "save_feather3d(train_labels_clean, 'train_labels_final')\n",
    "save_feather3d(test_labels_nooverlap, 'test_labels_final', force = True)\n",
    "save_feather3d(valid_labels_clean, 'valid_labels_final')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7.0710678118654755"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
